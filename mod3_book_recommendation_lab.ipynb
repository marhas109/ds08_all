{"cells":[{"cell_type":"markdown","metadata":{"id":"nqh2eUoElDEm"},"source":["# Recommendation Systems Lab: Building and Evaluating Book Recommenders\n","\n","## Business Scenario\n","\n","You work as a data scientist for ReadMore, an online bookstore that wants to improve user engagement through better book recommendations. The company has collected data on user ratings for various books and wants to build a recommendation system that can suggest books users are likely to enjoy.\n","\n","Your task is to build and evaluate different recommendation algorithms using the Surprise library. This will allow ReadMore to personalize content for users and ultimately increase user satisfaction and conversion rates.\n","\n","### RMSE as a Key Metric for Recommendation Systems\n","\n","In the context of recommendation systems, Root Mean Square Error (RMSE) is a critical metric that measures the accuracy of predicted ratings. A lower RMSE indicates a more accurate recommendation system.\n","\n","Why RMSE Matters for Book Recommendations:\n","\n","- It measures the average magnitude of prediction errors\n","- It penalizes larger errors more heavily than smaller ones\n","- It's directly interpretable in the same units as the original ratings\n","- It allows for easy comparison between different recommendation algorithms\n","\n","For ReadMore, minimizing RMSE means their recommendations will more closely match users' actual preferences, leading to:\n","- Increased user satisfaction\n","- Higher conversion rates for recommended books\n","- Enhanced user retention and platform loyalty\n","- More effective cross-selling opportunities\n","\n","**You are expected to use RMSE to score and evaluate your recommendation models.**\n","\n","## The Process\n","\n","By the end of this lab, you will have:\n","1. Loaded and prepared data for Surprise modeling\n","2. Compared different recommendation algorithms\n","3. Tuned the hyperparameters of the best-performing algorithm\n","4. Evaluated the final model\n","5. Generated recommendations for specific users\n"]},{"cell_type":"markdown","metadata":{"id":"QNKY9fFwlDEn"},"source":["## Step 0: Setup - Import Libraries\n","\n","First, let's import all the necessary libraries for our recommendation system lab."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5DZuehcFlDEo"},"outputs":[],"source":["# CodeGrade step0\n","# Import required libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Surprise library imports\n","from surprise import Dataset, Reader\n","from surprise import SVD, KNNBasic, KNNWithMeans, NMF, BaselineOnly\n","from surprise.model_selection import train_test_split, cross_validate, GridSearchCV, KFold\n","from surprise import accuracy\n","\n","# Set random seed for reproducibility\n","np.random.seed(42)"]},{"cell_type":"markdown","metadata":{"id":"jInjOtLClDEo"},"source":["## Step 1: Load and Prepare Ratings Data\n","\n","The data provided contains user ratings for 1000 different book ids, on a rating scale of 1-5."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FvI-RWzLlDEo"},"outputs":[],"source":["# CodeGrade step0\n","# Load in book ratings data\n","ratings_df = pd.read_csv('book_ratings.csv')\n","ratings_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zO0q8jq6lDEo"},"outputs":[],"source":["# Run this cell without changes\n","# Basic statistics about the generated dataset\n","print(f\"Number of users: {len(ratings_df['user_id'].unique())}\")\n","print(f\"Number of books: {len(ratings_df['book_id'].unique())}\")\n","print(f\"Number of ratings: {len(ratings_df)}\")\n","print(f\"Rating distribution:\\n{ratings_df['rating'].value_counts().sort_index()}\")\n","print(f\"Average rating: {ratings_df['rating'].mean():.2f}\")\n","\n","# Plot rating distribution\n","plt.figure(figsize=(10, 6))\n","sns.countplot(x='rating', data=ratings_df, hue='rating', legend=False)\n","plt.title('Rating Distribution', fontsize=14)\n","plt.xlabel('Rating', fontsize=12)\n","plt.ylabel('Count', fontsize=12)\n","plt.xticks(fontsize=10)\n","plt.yticks(fontsize=10)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ynPA3_M-lDEo"},"source":["### Prepare Data for Surprise\n","\n","Now, let's load our ratings data into a format suitable for the Surprise library."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xLecaRtDlDEp"},"outputs":[],"source":["# CodeGrade step1\n","# Replace None with your code\n","# Create a Reader object and specify the rating scale\n","reader = None\n","\n","# Load the data into the Surprise Dataset format\n","data = None\n","\n","# Split the data into training and testing sets (75-25 split, random_state=42)\n","trainset, testset = None"]},{"cell_type":"markdown","metadata":{"id":"-QoWspxqlDEp"},"source":["## Part 2: Algorithm Comparison\n","\n","Now, let's compare different recommendation algorithms to see which one performs best on our dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hB6d9qG_lDEp"},"outputs":[],"source":["# CodeGrade step2\n","# Replace None with your code\n","# Define a list of algorithms to compare\n","algorithms = [\n","    SVD(random_state=42),\n","    KNNBasic(sim_options={'user_based': True}),  # User-based collaborative filtering\n","    KNNBasic(sim_options={'user_based': False}), # Item-based collaborative filtering\n","    KNNWithMeans(sim_options={'user_based': True}),\n","    NMF(random_state=42)\n","]\n","\n","results = {}\n","\n","for algo in algorithms:\n","    # Get the algorithm name\n","    algo_name = None\n","\n","    # For KNN algorithms, add user/item-based information\n","    if algo_name.startswith('KNN'):\n","        user_based = None\n","        algo_name = None\n","\n","    # Perform 5-fold cross-validation\n","    cv_results = None\n","\n","    # Store the results\n","    results[algo_name] = {\n","        'RMSE': None,\n","        'MAE': None}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f1jIyl08lDEp"},"outputs":[],"source":["# Run this cell without changes\n","# Create a DataFrame from the results for easier visualization\n","results_df = pd.DataFrame({\n","    'Algorithm': list(results.keys()),\n","    'RMSE': [results[algo]['RMSE'] for algo in results],\n","    'MAE': [results[algo]['MAE'] for algo in results]\n","})\n","\n","# Display the results table\n","print(\"Algorithm Comparison:\")\n","print(results_df.sort_values('RMSE'))\n","\n","# Visualize RMSE comparison\n","plt.figure(figsize=(12, 6))\n","ax = sns.barplot(x='Algorithm', y='RMSE', data=results_df, hue='Algorithm', legend=False)\n","plt.title('RMSE Comparison Across Algorithms', fontsize=14)\n","plt.xlabel('Algorithm', fontsize=12)\n","plt.ylabel('RMSE (lower is better)', fontsize=12)\n","plt.xticks(rotation=45, ha='right')\n","plt.tight_layout()\n","\n","# Add value labels on top of bars\n","for i, p in enumerate(ax.patches):\n","    ax.annotate(f'{p.get_height():.4f}',\n","                (p.get_x() + p.get_width() / 2., p.get_height()),\n","                ha = 'center', va = 'bottom',\n","                fontsize=10,\n","                rotation=0,\n","                xytext=(0, 5),\n","                textcoords='offset points')\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"aY8C74thlDEp"},"source":["## Part 3: Hyperparameter Tuning for SVD\n","\n","Let's attempt to improve the SVD model by performing hyperparameter tuning. Given that it is the most complex we think there is this most room for improvement via tuning."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nt2iHKzblDEp"},"outputs":[],"source":["# CodeGrade step3\n","# Replace None with your code\n","# We'll assume SVD is the best algorithm for this example\n","# Define the parameter grid for SVD\n","param_grid = {\n","    'n_factors': [100, 150, 200],\n","    'n_epochs': [20, 30, 40],\n","    'lr_all': [0.005, 0.01, 0.05],\n","    'reg_all': [0.05, 0.1, 0.15],\n","    'random_state': [42]\n","}\n","\n","# Perform grid search to find the best hyperparameters\n","grid_search = GridSearchCV(None, None, cv=KFold(3, random_state=42))\n","\n","# Fit the grid search to the data\n","None\n","\n","# Get the best parameters and score\n","best_params_rmse = None\n","best_score_rmse = None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YAICVTJslDEq"},"outputs":[],"source":["# Run this cell without changes\n","# Print the best parameters and score\n","print(f\"Best RMSE: {best_score_rmse}\")\n","print(f\"Best parameters: {best_params_rmse}\")"]},{"cell_type":"markdown","metadata":{"id":"geoNkN-rlDEq"},"source":["## Part 4: Final Model Evaluation\n","\n","Now, let's train a final model with the best hyperparameters and evaluate its performance on the test set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ihg9WMd8lDEq"},"outputs":[],"source":["# CodeGrade step4\n","# Replace None with your code\n","# Create a final model with the best parameters (can use grid search to extract or create new)\n","final_model = None\n","\n","# Train the model on training\n","None\n","\n","# Make predictions on the test set\n","final_predictions = None\n","\n","# Calculate RMSE on the test set\n","final_rmse = None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tTfjK24SlDEq"},"outputs":[],"source":["# Run this cell without changes\n","print(f\"Untuned Model Evaluation (CV RMSE): {results['SVD']['RMSE']}\")\n","print(f\"Final Model Tuned (CV RMSE): {best_score_rmse}\")\n","print(f\"Final Model Evaluation (Testset RMSE): {final_rmse}\")"]},{"cell_type":"markdown","metadata":{"id":"dibM_YVTlDEq"},"source":["## Part 5: Generating Final Recommendations\n","\n","Finally, let's create a comprehensive function that can provide book recommendations for any user using our tuned model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cqXZsBQWlDEq"},"outputs":[],"source":["# CodeGrade step5\n","# Replace None with your code\n","# Build full trainset with all users\n","full_trainset = None\n","# Fit final model to full trainset\n","None\n","\n","def get_top_n_recommendations(model, data, user_id, n=10):\n","    \"\"\"\n","    Generate top-N recommendations for a specific user\n","\n","    Parameters:\n","    -----------\n","    model : surprise algorithm instance\n","        Trained model\n","    data : surprise.Trainset\n","        Full trainset (created above)\n","    user_id : str\n","        ID of the user for whom to generate recommendations\n","    n : int, default=10\n","        Number of recommendations to generate\n","\n","    Returns:\n","    --------\n","    list of tuples\n","        (book_id, predicted_rating) sorted by predicted rating in descending order\n","    \"\"\"\n","    # Get a list of all items\n","    all_items = None\n","\n","    # Convert raw user ID to inner ID used by the trainset\n","    try:\n","        inner_user_id = None\n","    except ValueError:\n","        print(f\"User {user_id} doesn't exist in the data set\")\n","        return []\n","\n","    # Get items rated by this user\n","    user_items = None\n","\n","    # Find items not rated by the user\n","    unrated_items = None\n","\n","    # Predict ratings for unrated items\n","    predictions = []\n","    for item_id in unrated_items:\n","        # Convert inner item ID back to raw ID for prediction\n","        raw_item_id = None\n","        # Get prediction\n","        pred = None\n","        predictions.append(None)\n","\n","    # Sort predictions by estimated rating (highest first)\n","    None\n","\n","    # Return top n recommendations\n","    return None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OY-4e_JTlDEq"},"outputs":[],"source":["# Run this cell without changes\n","# Test the recommendation function with a specific user\n","test_user_id = 150\n","\n","# Get recommendations for the test user\n","top_recommendations = get_top_n_recommendations(final_model, full_trainset, test_user_id, n=5)\n","\n","# Display recommendations\n","print(f\"Top 5 Book Recommendations for User {test_user_id}:\")\n","for i, (book_id, predicted_rating) in enumerate(top_recommendations, 1):\n","    print(f\"{i}. Book ID: {book_id} - Predicted Rating: {predicted_rating:.2f}\")"]},{"cell_type":"markdown","metadata":{"id":"6fqv9l8zlDEq"},"source":["## Conclusion\n","\n","Congratulations! You've successfully built a book recommendation system using the Surprise library. You've learned how to:\n","\n","1. Prepare data for the Surprise library\n","2. Compare different recommendation algorithms\n","3. Tune hyperparameters to improve performance\n","4. Evaluate recommendation systems in Surprise\n","5. Create a comprehensive recommendation function\n","\n","This knowledge can be applied to real-world recommendation systems across various domains like e-commerce, content streaming, news articles, and more."]}],"metadata":{"kernelspec":{"display_name":"Python (Cohort_Env)","language":"python","name":"cohort_env"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}