{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis Lab: Hospital Patient Data\n",
    "\n",
    "## Business Scenario\n",
    "You've recently joined a healthcare analytics team as a junior data scientist. Your team is working with a hospital network that wants to improve their resource allocation and patient care strategies. The hospital has collected data on patient admissions over the past year, including various health metrics, demographics, and length of stay.\n",
    "\n",
    "The challenge is that the dataset contains numerous features, making it difficult to visualize patterns and extract meaningful insights. The hospital administrators need to understand the underlying factors that drive variation in patient data to make more informed decisions about resource allocation and patient care protocols.\n",
    "\n",
    "Your task is to apply Principal Component Analysis (PCA) to this healthcare dataset to reduce its dimensionality while preserving the most important information. By extracting the principal components that explain most of the variance, you'll help the hospital administrators visualize and understand the key factors affecting their patient population.\n",
    "\n",
    "You'll follow the seven-step PCA process covered in the lesson:\n",
    "1. Prepare your data\n",
    "2. Explore feature relationships\n",
    "3. Implement PCA transformation\n",
    "4. Analyze variance explained\n",
    "5. Select optimal components\n",
    "6. Interpret principal components\n",
    "7. Visualize and apply transformed data\n",
    "\n",
    "## Data Overview\n",
    "The provided file hospital_patients.csv contains simulated patient data with the following features:\n",
    "- Age\n",
    "- BMI (Body Mass Index)\n",
    "- Blood pressure (systolic)\n",
    "- Blood glucose levels\n",
    "- Cholesterol levels\n",
    "- Temperature\n",
    "- White blood cell count\n",
    "- Red blood cell count\n",
    "- Oxygen saturation\n",
    "- Respiratory rate\n",
    "- Heart rate\n",
    "- Length of stay (days)\n",
    "\n",
    "## Step 0: Load imports and Data\n",
    "\n",
    "First, load the dataset and get familiar with its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CodeGrade step0\n",
    "# Run this cell without changes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load the patient data\n",
    "patients_df = pd.read_csv('hospital_patients.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "# Display the first few rows and basic information\n",
    "print(patients_df.head())\n",
    "print(\"\\nDataset Info:\")\n",
    "print(patients_df.info())\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(patients_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Prepare Data\n",
    "\n",
    "Now, preprocess and standardize the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CodeGrade step1\n",
    "# Select features for PCA (exclude length_of_stay as it's a target variable)\n",
    "# List of column names for features\n",
    "features = None\n",
    "\n",
    "# Create a feature df X\n",
    "X = None\n",
    "\n",
    "# Standardize the features (critical for PCA)\n",
    "scaler = StandardScaler()\n",
    "X_std = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Explore Feature Relationships\n",
    "Before applying PCA, it's important to understand the relationships between features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CodeGrade step2\n",
    "# Calculate and visualize the correlation matrix (use pandas) of unscaled data for features\n",
    "corr_matrix = None\n",
    "\n",
    "# Create correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', square=True)\n",
    "plt.title('Correlation Matrix of Patient Health Metrics')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create scatter plot matrix (pairplot) of unscaled feature data\n",
    "plt.figure(figsize=(12, 10))\n",
    "pair = sns.pairplot(None, vars=None, hue='length_of_stay', \n",
    "             palette='viridis', diag_kind='kde', plot_kws={'alpha': 0.6})\n",
    "plt.suptitle('Scatter Plot Matrix of Selected Patient Features', y=1.02, fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Implement PCA Transformation\n",
    "Now apply PCA to transform the data to the principal component space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CodeGrade step3\n",
    "# Initialize PCA without restricting the number of components\n",
    "pca = None\n",
    "\n",
    "# Fit PCA model to scaled data\n",
    "None\n",
    "\n",
    "# Get explained variance ratio\n",
    "explained_variance_ratio = None\n",
    "\n",
    "# Transform the standardized data to get principal components\n",
    "X_pca = None\n",
    "\n",
    "# Create a DataFrame with the principal components\n",
    "pca_df = pd.DataFrame(\n",
    "    data=X_pca,\n",
    "    columns=[f'PC{i+1}' for i in range(X_pca.shape[1])]\n",
    ")\n",
    "pca_df['length_of_stay'] = patients_df['length_of_stay']\n",
    "\n",
    "# Calculate cumulative explained variance using numpy\n",
    "cumulative_variance = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "# Print explained variance ratio for each component\n",
    "for i, ratio in enumerate(explained_variance_ratio):\n",
    "    print(f\"Principal Component {i+1}: {ratio:.4f} of variance explained\")\n",
    "print(\"\\nCumulative explained variance:\")\n",
    "for i, cum_var in enumerate(cumulative_variance):\n",
    "    print(f\"First {i+1} components: {cum_var:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Analyze Variance Explained\n",
    "Create visualizations to help determine the optimal number of components to retain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CodeGrade step4\n",
    "# Create a scree plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "scree_plot = plt.plot(range(1, len(None) + 1), None, \n",
    "         'o-', linewidth=2, color='blue')\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Variance Explained')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Create a cumulative variance plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "cum_var_plot = plt.plot(range(1, len(None) + 1), None, \n",
    "         'o-', linewidth=2, color='green')\n",
    "# Add lines for 90% and 95% thresholds\n",
    "plt.axhline(y=0.9, color='r', linestyle='--', label='90% threshold')\n",
    "plt.axhline(y=0.95, color='g', linestyle='--', label='95% threshold')\n",
    "plt.title('Cumulative Variance Explained')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Variance Explained')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Create a Kaiser criterion plot (eigenvalues > 1)\n",
    "eigenvalues = None\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "kaiser_plot = plt.plot(range(1, len(eigenvalues) + 1), eigenvalues, \n",
    "         'o-', linewidth=2, color='purple')\n",
    "plt.axhline(y=1.0, color='r', linestyle='--', label='Eigenvalue = 1.0')\n",
    "plt.title('Kaiser Criterion')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Eigenvalue')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Select Optimal Components and Transform Data\n",
    "Based on your analysis of variance, select the optimal number of components and transform the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CodeGrade step5\n",
    "# Determine optimal number of components using different methods\n",
    "\n",
    "# Based on cumulative variance threshold (e.g., 95%)\n",
    "target_variance = 0.95\n",
    "n_components_variance =  None\n",
    "\n",
    "# Based on Kaiser criterion\n",
    "n_components_kaiser = None\n",
    "\n",
    "# Choose the optimal number of components based on variance explained threshold\n",
    "n_components_optimal = None\n",
    "\n",
    "# Create a new PCA model with the optimal number of components\n",
    "pca_optimal = None\n",
    "\n",
    "# Transform standarized data using pca_optimal\n",
    "X_pca_optimal = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "print(f\"Components needed for {target_variance*100}% variance: {n_components_variance}\")\n",
    "print(f\"Components with eigenvalues > 1: {n_components_kaiser}\")\n",
    "print(f\"Selected {n_components_optimal} components based on analysis\")\n",
    "\n",
    "# Display dimensionality reduction statistics\n",
    "print(f\"Original data dimensionality: {X.shape[1]}\")\n",
    "print(f\"Reduced data dimensionality: {X_pca_optimal.shape[1]}\")\n",
    "print(f\"Dimensionality reduction: {X.shape[1]} â†’ {X_pca_optimal.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Interpret Principal Components\n",
    "Analyze what each principal component represents in terms of the original features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CodeGrade step6\n",
    "# Create a DataFrame to display loadings\n",
    "loadings = pd.DataFrame(\n",
    "    None,\n",
    "    columns=[f'PC{i+1}' for i in range(n_components_optimal)],\n",
    "    index=None\n",
    ")\n",
    "\n",
    "# Visualize the loadings for the first two PCs\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, feature in enumerate(features):\n",
    "    plt.arrow(0, 0, loadings.iloc[i, 0], loadings.iloc[i, 1], head_width=0.05, head_length=0.05)\n",
    "    plt.text(loadings.iloc[i, 0]*1.1, loadings.iloc[i, 1]*1.1, feature, fontsize=12)\n",
    "\n",
    "# Add a unit circle for reference\n",
    "circle = plt.Circle((0, 0), 1, fill=False, linestyle='--')\n",
    "plt.gca().add_patch(circle)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
    "plt.axvline(x=0, color='k', linestyle='-', alpha=0.3)\n",
    "plt.xlim(-1.1, 1.1)\n",
    "plt.ylim(-1.1, 1.1)\n",
    "plt.title('PCA Loading Plot (PC1 vs PC2)')\n",
    "plt.xlabel(f'PC1 ({pca_optimal.explained_variance_ratio_[0]:.2%} variance explained)')\n",
    "plt.ylabel(f'PC2 ({pca_optimal.explained_variance_ratio_[1]:.2%} variance explained)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identify most important features for each component\n",
    "# A feature is considered important if its absolute loading is above a threshold\n",
    "threshold = 0.3  # Common threshold for significance\n",
    "\n",
    "# Find important features for each component\n",
    "important_features = {}\n",
    "for i in range(n_components_optimal):\n",
    "    # Get the absolute loadings for this component\n",
    "    abs_loadings = abs(loadings.iloc[:, i])\n",
    "    # Get indices of features with loadings above threshold\n",
    "    important_indices = np.where(abs_loadings > threshold)[0]\n",
    "    # Get the feature names and their loadings\n",
    "    imp_features = [(features[j], loadings.iloc[j, i]) for j in important_indices]\n",
    "    # Sort by absolute loading value (descending)\n",
    "    imp_features = sorted(imp_features, key=lambda x: abs(x[1]), reverse=True)\n",
    "    important_features[i] = imp_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "print(\"Component loadings (weights of original features in each PC):\")\n",
    "print(loadings)\n",
    "\n",
    "# Interpret the first 3 components (or fewer if you chose fewer components)\n",
    "for i in range(min(3, n_components_optimal)):\n",
    "    print(f\"\\nPrincipal Component {i+1} interpretation:\")\n",
    "    print(f\"Explained variance: {pca_optimal.explained_variance_ratio_[i]:.2%}\")\n",
    "    print(\"Important features and their loadings:\")\n",
    "    for feature, loading in important_features[i]:\n",
    "        print(f\"  {feature}: {loading:.4f}\")\n",
    "    \n",
    "    # Interpretation example\n",
    "    if i == 0:\n",
    "        print(\"This component appears to represent: Overall health status and severity\")\n",
    "    elif i == 1:\n",
    "        print(\"This component appears to represent: Metabolic factors (glucose, cholesterol)\")\n",
    "    else:\n",
    "        print(\"This component appears to represent: Inflammatory response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Visualize and Apply Transformed Data\n",
    "Visualize the data in the reduced-dimensional space and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CodeGrade step7\n",
    "# Extract the first two principal component features from X_pca_optimal\n",
    "comp_1 = None\n",
    "comp_2 = None\n",
    "\n",
    "# Create a scatter plot of the first two principal components\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(\n",
    "    comp_1,\n",
    "    comp_2,\n",
    "    c=patients_df['length_of_stay'],\n",
    "    cmap='viridis',\n",
    "    alpha=0.7,\n",
    "    s=50\n",
    ")\n",
    "\n",
    "plt.title('Patient Data in Principal Component Space')\n",
    "plt.xlabel(f'Principal Component 1 ({pca_optimal.explained_variance_ratio_[0]:.2%} variance)')\n",
    "plt.ylabel(f'Principal Component 2 ({pca_optimal.explained_variance_ratio_[1]:.2%} variance)')\n",
    "plt.grid(True)\n",
    "plt.colorbar(scatter, label='Length of Stay (days)')\n",
    "plt.show()\n",
    "\n",
    "# If you have 3+ components, create a 3D scatter plot\n",
    "if n_components_optimal >= 3:\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    sc = ax.scatter(\n",
    "        X_pca_optimal[:, 0],\n",
    "        X_pca_optimal[:, 1],\n",
    "        X_pca_optimal[:, 2],\n",
    "        c=patients_df['length_of_stay'],\n",
    "        cmap='viridis',\n",
    "        alpha=0.7,\n",
    "        s=50\n",
    "    )\n",
    "    \n",
    "    ax.set_title('Patient Data in 3D Principal Component Space')\n",
    "    ax.set_xlabel(f'PC1 ({pca_optimal.explained_variance_ratio_[0]:.2%})')\n",
    "    ax.set_ylabel(f'PC2 ({pca_optimal.explained_variance_ratio_[1]:.2%})')\n",
    "    ax.set_zlabel(f'PC3 ({pca_optimal.explained_variance_ratio_[2]:.2%})')\n",
    "    fig.colorbar(sc, ax=ax, label='Length of Stay (days)')\n",
    "    plt.show()\n",
    "\n",
    "# Reconstruct the original data from the PCA representation\n",
    "X_reconstructed = None\n",
    "\n",
    "# Calculate mean squared error between original and reconstructed data\n",
    "reconstruction_error = None\n",
    "print(f\"Mean squared reconstruction error: {reconstruction_error:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Cohort_Env)",
   "language": "python",
   "name": "cohort_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
