{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39aad98e",
   "metadata": {},
   "source": [
    "Let's walk through building a movie recommendation system at \"StreamFlix,\" a fictional streaming service where you've just been hired as a junior data scientist. Your first project is to implement different types of recommendation algorithms using the Surprise library to see which performs best for their user base."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53039651",
   "metadata": {},
   "source": [
    "#### The Business Challenge ####\n",
    "\n",
    "StreamFlix has a growing catalog of movies but struggles with user engagement. Customer research shows that users often spend more time searching for content than watching it: a problem known in the industry as \"choice paralysis.\" Your manager has asked you to develop a recommendation system that will help users discover movies they'll enjoy, which should increase watch time and reduce churn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ac5ce4",
   "metadata": {},
   "source": [
    "##### Setting Up the Environment #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90e1a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "!pip install numpy pandas scikit-surprise\n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, KNNBasic, SVD, accuracy\n",
    "from surprise.model_selection import train_test_split, cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b47bdc9",
   "metadata": {},
   "source": [
    "##### Load and Prepare the Data #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a87685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "ratings = pd.read_csv('streamflix_ratings.csv')\n",
    "print(ratings.head())\n",
    "\n",
    "# Output:\n",
    "#    user_id  movie_id  rating  timestamp\n",
    "# 0        1      1193     5.0  978300760\n",
    "# 1        1       661     3.0  978302109\n",
    "# 2        1       914     3.0  978301968\n",
    "# 3        1      3408     4.0  978300275\n",
    "# 4        1      2355     5.0  978824291"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95056d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data into a format Surprise can use\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(ratings[['user_id', 'movie_id', 'rating']], reader)\n",
    "\n",
    "# Create a training and testing set using surprise\n",
    "trainset, testset = train_test_split(data, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddaccff",
   "metadata": {},
   "source": [
    "##### Collaborative Filtering #####\n",
    "\n",
    "*User-based collaborative filtering*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba9fed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-based collaborative filtering\n",
    "user_based = KNNBasic(k=50, sim_options={'name': 'pearson', 'user_based': True})\n",
    "user_based.fit(trainset)\n",
    "\n",
    "# Make predictions on the test set\n",
    "user_based_predictions = user_based.test(testset)\n",
    "\n",
    "# Evaluate the performance\n",
    "user_accuracy = accuracy.rmse(user_based_predictions)\n",
    "print(f\"User-based CF RMSE: {user_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efacecf7",
   "metadata": {},
   "source": [
    "*Item-based collaborative fitering*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f83393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item-based collaborative filtering\n",
    "item_based = KNNBasic(k=50, sim_options={'name': 'pearson', 'user_based': False})\n",
    "item_based.fit(trainset)\n",
    "\n",
    "# Make predictions on the test set\n",
    "item_based_predictions = item_based.test(testset)\n",
    "\n",
    "# Evaluate the performance\n",
    "item_accuracy = accuracy.rmse(item_based_predictions)\n",
    "print(f\"Item-based CF RMSE: {item_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fe09c1",
   "metadata": {},
   "source": [
    "##### Matrix Factorization #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bb588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix Factorization using SVD\n",
    "svd_model = SVD(n_factors=100, n_epochs=20, lr_all=0.005, reg_all=0.02)\n",
    "svd_model.fit(trainset)\n",
    "\n",
    "# Make predictions on the test set\n",
    "svd_predictions = svd_model.test(testset)\n",
    "\n",
    "# Evaluate the performance\n",
    "svd_accuracy = accuracy.rmse(svd_predictions)\n",
    "print(f\"Matrix Factorization RMSE: {svd_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15983333",
   "metadata": {},
   "source": [
    "##### Content-Based Filtering with Movie Features #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f219a8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load movie features\n",
    "movie_features = pd.read_csv('movie_features.csv')\n",
    "\n",
    "# Create a custom content-based algorithm\n",
    "from surprise import AlgoBase\n",
    "import numpy as np\n",
    "\n",
    "class ContentBasedAlgorithm(AlgoBase):\n",
    "    def __init__(self, movie_features_df):\n",
    "        AlgoBase.__init__(self)\n",
    "        self.movie_features = {}\n",
    "        \n",
    "        # Convert movie features to a dictionary for faster lookup\n",
    "        for _, row in movie_features_df.iterrows():\n",
    "            movie_id = row['movie_id']\n",
    "            # Convert genre features to a numpy array\n",
    "            features = row[['action', 'adventure', 'comedy', 'drama', 'fantasy', \n",
    "                            'horror', 'romance', 'sci_fi', 'thriller']].values\n",
    "            self.movie_features[movie_id] = features\n",
    "    \n",
    "    def fit(self, trainset):\n",
    "        AlgoBase.fit(self, trainset)\n",
    "        \n",
    "        # Create user profiles based on their rated movies\n",
    "        self.user_profiles = {}\n",
    "        for u in trainset.all_users():\n",
    "            # Get all movies this user has rated\n",
    "            items_rated = [j for (j, _) in trainset.ur[u]]\n",
    "            \n",
    "            if not items_rated:\n",
    "                # Handle users with no ratings\n",
    "                self.user_profiles[u] = np.zeros(9)  # 9 genre features\n",
    "                continue\n",
    "                \n",
    "            # Average the features of all movies this user has rated\n",
    "            features = [self.movie_features.get(self.trainset.to_raw_iid(j), np.zeros(9)) \n",
    "                       for j in items_rated if self.trainset.to_raw_iid(j) in self.movie_features]\n",
    "            \n",
    "            if features:\n",
    "                self.user_profiles[u] = np.mean(features, axis=0)\n",
    "            else:\n",
    "                self.user_profiles[u] = np.zeros(9)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def estimate(self, u, i):\n",
    "        if not (self.trainset.knows_user(u) and self.trainset.knows_item(i)):\n",
    "            return self.trainset.global_mean\n",
    "        \n",
    "        # Get the raw movie id\n",
    "        raw_movie_id = self.trainset.to_raw_iid(i)\n",
    "        \n",
    "        # If we don't have features for this movie, return global mean\n",
    "        if raw_movie_id not in self.movie_features:\n",
    "            return self.trainset.global_mean\n",
    "        \n",
    "        # Calculate cosine similarity between user profile and movie features\n",
    "        user_vector = self.user_profiles[u]\n",
    "        movie_vector = self.movie_features[raw_movie_id]\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if np.all(user_vector == 0) or np.all(movie_vector == 0):\n",
    "            return self.trainset.global_mean\n",
    "        \n",
    "        cos_sim = np.dot(user_vector, movie_vector) / (np.linalg.norm(user_vector) * np.linalg.norm(movie_vector))\n",
    "        \n",
    "        # Convert similarity to rating scale (1-5)\n",
    "        # Map similarity from [-1, 1] to [1, 5]\n",
    "        predicted_rating = 1 + 2 * (cos_sim + 1)\n",
    "        \n",
    "        return predicted_rating\n",
    "\n",
    "# Create an instance of our content-based algorithm\n",
    "cb_algo = ContentBasedAlgorithm(movie_features)\n",
    "cb_algo.fit(trainset)\n",
    "\n",
    "# Make predictions\n",
    "cb_predictions = cb_algo.test(testset)\n",
    "\n",
    "# Evaluate\n",
    "cb_accuracy = accuracy.rmse(cb_predictions)\n",
    "print(f\"Content-based filtering RMSE: {cb_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f769434b",
   "metadata": {},
   "source": [
    "##### Building a Hybrid Recommendation System #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e85b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple weighted hybrid: Combine SVD and content-based predictions\n",
    "class HybridRecommender:\n",
    "    def __init__(self, cf_algo, cb_algo, cf_weight=0.7):\n",
    "        self.cf_algo = cf_algo  # Collaborative filtering algorithm\n",
    "        self.cb_algo = cb_algo  # Content-based algorithm\n",
    "        self.cf_weight = cf_weight\n",
    "    \n",
    "    def predict(self, user_id, movie_id):\n",
    "        # Get predictions from both algorithms\n",
    "        try:\n",
    "            cf_pred = self.cf_algo.predict(user_id, movie_id).est\n",
    "        except:\n",
    "            cf_pred = 3.0  # Default if prediction fails\n",
    "        \n",
    "        try:\n",
    "            cb_pred = self.cb_algo.predict(user_id, movie_id).est\n",
    "        except:\n",
    "            cb_pred = 3.0  # Default if prediction fails\n",
    "        \n",
    "        # Combine predictions with weighted average\n",
    "        hybrid_pred = (self.cf_weight * cf_pred) + ((1 - self.cf_weight) * cb_pred)\n",
    "        \n",
    "        return hybrid_pred\n",
    "\n",
    "# Create the hybrid recommender\n",
    "hybrid = HybridRecommender(svd_model, cb_algo, cf_weight=0.7)\n",
    "\n",
    "# Evaluate on testset\n",
    "hybrid_predictions = []\n",
    "for uid, iid, true_r in testset:\n",
    "    pred = hybrid.predict(uid, iid)\n",
    "    hybrid_predictions.append((uid, iid, true_r, pred))\n",
    "\n",
    "# Calculate RMSE manually\n",
    "def calculate_rmse(predictions):\n",
    "    sum_squared_diff = 0\n",
    "    for _, _, true_r, pred_r in predictions:\n",
    "        sum_squared_diff += (true_r - pred_r) ** 2\n",
    "    return np.sqrt(sum_squared_diff / len(predictions))\n",
    "\n",
    "hybrid_rmse = calculate_rmse(hybrid_predictions)\n",
    "print(f\"Hybrid recommender RMSE: {hybrid_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9773d2fd",
   "metadata": {},
   "source": [
    "##### Implementing Top-N Recommendations #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2056932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get top N recommendations for a user\n",
    "def get_top_n_recommendations(user_id, n=10, algorithm=svd_model, movies_df=None):\n",
    "    \"\"\"\n",
    "    Generate top N movie recommendations for a specific user\n",
    "    \n",
    "    Parameters:\n",
    "    user_id: The user ID\n",
    "    n: Number of recommendations\n",
    "    algorithm: Trained recommendation algorithm\n",
    "    movies_df: DataFrame with movie information\n",
    "    \n",
    "    Returns:\n",
    "    List of (movie_id, predicted_rating) tuples\n",
    "    \"\"\"\n",
    "    # Get a list of all movies\n",
    "    all_movie_ids = ratings['movie_id'].unique()\n",
    "    \n",
    "    # Get movies this user has already rated\n",
    "    user_ratings = ratings[ratings['user_id'] == user_id]['movie_id'].unique()\n",
    "    \n",
    "    # Movies the user hasn't rated\n",
    "    movies_to_predict = np.setdiff1d(all_movie_ids, user_ratings)\n",
    "    \n",
    "    # Predict ratings for all unrated movies\n",
    "    predictions = [algorithm.predict(user_id, movie_id) for movie_id in movies_to_predict]\n",
    "    \n",
    "    # Sort predictions by estimated rating\n",
    "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "    \n",
    "    # Take top N\n",
    "    top_n = predictions[:n]\n",
    "    \n",
    "    if movies_df is not None:\n",
    "        # Return movie information along with predictions\n",
    "        result = []\n",
    "        for pred in top_n:\n",
    "            movie_info = movies_df[movies_df['movie_id'] == pred.iid]\n",
    "            if not movie_info.empty:\n",
    "                result.append((movie_info['title'].values[0], pred.est))\n",
    "        return result\n",
    "    else:\n",
    "        # Just return movie IDs and predicted ratings\n",
    "        return [(pred.iid, pred.est) for pred in top_n]\n",
    "\n",
    "# Load movie information\n",
    "movies = pd.read_csv('movies.csv')\n",
    "\n",
    "# Get recommendations for a specific user\n",
    "user_recommendations = get_top_n_recommendations(\n",
    "    user_id=42, n=5, algorithm=svd_model, movies_df=movies)\n",
    "\n",
    "print(\"Top 5 recommendations for user 42:\")\n",
    "for title, est in user_recommendations:\n",
    "    print(f\"{title} (predicted rating: {est:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2b4654",
   "metadata": {},
   "source": [
    "##### Metrics to Evaluate Impact #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c7ab12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the business impact using historical data\n",
    "def estimate_business_impact(algorithm, holdout_data):\n",
    "    \"\"\"\n",
    "    Estimate business impact of recommendations\n",
    "    \n",
    "    Parameters:\n",
    "    algorithm: Trained recommendation algorithm\n",
    "    holdout_data: Data held out for testing\n",
    "    \n",
    "    Returns:\n",
    "    Dictionary with impact metrics\n",
    "    \"\"\"\n",
    "    # Predict ratings for holdout data\n",
    "    predictions = algorithm.test(holdout_data)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    rmse = accuracy.rmse(predictions)\n",
    "    \n",
    "    # Estimate potential improvements\n",
    "    # Assume that recommendations above 4.0 would lead to a watch\n",
    "    potential_watches = sum(1 for pred in predictions if pred.est >= 4.0)\n",
    "    watch_rate = potential_watches / len(predictions)\n",
    "    \n",
    "    # Assuming average watch time of 100 minutes\n",
    "    additional_watch_minutes = potential_watches * 100\n",
    "    \n",
    "    # Assuming $10 monthly subscription and 30 hours of viewing per month being \"worth it\"\n",
    "    # Calculate potential reduced churn\n",
    "    monthly_minutes = 30 * 60  # 30 hours in minutes\n",
    "    subscription_value = 10  # $10 per month\n",
    "    churn_reduction_estimate = additional_watch_minutes / monthly_minutes * subscription_value\n",
    "    \n",
    "    return {\n",
    "        'rmse': rmse,\n",
    "        'potential_watches': potential_watches,\n",
    "        'watch_rate': watch_rate,\n",
    "        'additional_watch_minutes': additional_watch_minutes,\n",
    "        'estimated_churn_reduction_value': churn_reduction_estimate\n",
    "    }\n",
    "\n",
    "# Calculate impact metrics for the SVD model\n",
    "impact = estimate_business_impact(svd_model, testset)\n",
    "print(\"Estimated Business Impact:\")\n",
    "for metric, value in impact.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029bd0b1",
   "metadata": {},
   "source": [
    "##### Summary and Recommendations #####\n",
    "\n",
    "1. The Matrix Factorization (SVD) model performed best in terms of prediction accuracy with an RMSE of [value from your analysis].\n",
    "2. The hybrid approach combining collaborative and content-based filtering showed promising results for addressing the cold start problem.\n",
    "3. This analysis suggests the recommendation system could increase watch time by approximately [value] minutes per user and potentially reduce churn, translating to an estimated [value] in preserved subscription revenue.\n",
    "4. For immediate implementation, recommend deploying the SVD model for established users and the content-based approach for new users.\n",
    "5. In the next phase, suggest developing a more sophisticated hybrid system that also incorporates contextual information such as time of day and device type."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
